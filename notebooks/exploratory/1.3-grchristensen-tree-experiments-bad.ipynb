{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af609086-bd3c-43fe-8d84-016250bc0a2d",
   "metadata": {},
   "source": [
    "**DEPRECATED** - Enter at your own risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0127d4-672b-4579-9b58-d48e666e35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from optiver import Directories\n",
    "from optiver.bench import rmspe\n",
    "\n",
    "dirs = Directories(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb12082b-6da0-467e-8baa-95918499f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_split_df(train_features, train_targets, split):\n",
    "    split_feature, split_value = split\n",
    "    \n",
    "    left_bool_index = train_features[split_feature] <= split_value\n",
    "    right_bool_index = train_features[split_feature] > split_value\n",
    "    \n",
    "    train_features_left, train_targets_left = train_features[left_bool_index], train_targets[left_bool_index]\n",
    "    train_features_right, train_targets_right = train_features[right_bool_index], train_targets[right_bool_index]\n",
    "    \n",
    "    return (train_features_left, train_targets_left), (train_features_right, train_targets_right)\n",
    "\n",
    "\n",
    "def rss_from_mean(y):\n",
    "    return ((y.mean() - y)**2).sum()\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, *, value=None, split=None, left_tree=None, right_tree=None, annotations=None):\n",
    "        self.value = None\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            self.is_node = True\n",
    "        else:\n",
    "            self.split = split\n",
    "            self.left_tree = left_tree\n",
    "            self.right_tree = right_tree\n",
    "            self.is_node = False\n",
    "        \n",
    "        self.annotations = annotations or {}\n",
    "        \n",
    "    def clone(self):\n",
    "        if self.is_node:\n",
    "            tree = DecisionTree(value=self.value, annotations=self.annotations.copy())\n",
    "        else:\n",
    "            tree = DecisionTree(\n",
    "                split=self.split, left_tree=self.left_tree.clone(), right_tree=self.right_tree.clone(), annotations=self.annotations.copy()\n",
    "            )\n",
    "        \n",
    "        return tree\n",
    "    \n",
    "    def prune_best_cost(self, train_features, train_targets):\n",
    "        trees, means, costs = zip(*list(self.annotations_and_means(train_features, train_targets)))\n",
    "        \n",
    "        best_index = np.argmax(np.array(costs))\n",
    "        \n",
    "        if costs[best_index] < 0.:\n",
    "            return False\n",
    "        \n",
    "        trees[best_index].split = None\n",
    "        trees[best_index].left_tree = None\n",
    "        trees[best_index].right_tree = None\n",
    "        trees[best_index].is_node = True\n",
    "        trees[best_index].value = means[best_index]\n",
    "        trees[best_index].annotations = {}\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def annotations_and_means(self, train_features, train_targets):\n",
    "        if not self.is_node:\n",
    "            yield self, train_targets.mean(), self.annotations[\"cost\"]\n",
    "            \n",
    "            left_split, right_split = decision_split_df(train_features, train_targets, self.split)\n",
    "            \n",
    "            for tree, cost, mean in self.left_tree.annotations_and_means(*left_split):\n",
    "                yield tree, cost, mean\n",
    "                \n",
    "            for tree, cost, mean in self.right_tree.annotations_and_means(*right_split):\n",
    "                yield tree, cost, mean\n",
    "    \n",
    "    def paths(self):\n",
    "        return self._paths([])\n",
    "    \n",
    "    def _paths(self, partial_path):\n",
    "        if self.is_node:\n",
    "            yield partial_path, self.value\n",
    "        else:\n",
    "            if self.left_tree is not None:\n",
    "                new_path = partial_path + [(self.split, False)]\n",
    "                for path in self.left_tree._paths(new_path):\n",
    "                    yield path\n",
    "            \n",
    "            if self.right_tree is not None:\n",
    "                new_path = partial_path + [(self.split, True)]\n",
    "                for path in self.right_tree._paths(new_path):\n",
    "                    yield path\n",
    "                    \n",
    "    def classify(self, df):\n",
    "        values = pd.Series(0., index=df.index)\n",
    "        \n",
    "        for path, value in self.paths():\n",
    "            values[self.where_path_applies(df, path)] = value\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def where_path_applies(self, df, path):\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "        \n",
    "        for (split, choose_greater) in path:\n",
    "            feature, split_value = split\n",
    "            \n",
    "            values_greater = df[feature] >= split_value\n",
    "            \n",
    "            new_mask = df[feature] > split_value if choose_greater else df[feature] <= split_value\n",
    "            \n",
    "            mask = np.logical_and(mask, new_mask)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def prune_to_smallest_subtree(self, train_features, train_targets, threshold=1e-8):\n",
    "        self.annotate_errors(train_features, train_targets)\n",
    "        \n",
    "        while self._prune_to_smallest_subtree(threshold=threshold):\n",
    "            pass\n",
    "    \n",
    "    def _prune_to_smallest_subtree(self, threshold):\n",
    "        if not self.is_node:\n",
    "            if self.left_tree.is_node and self.right_tree.is_node:\n",
    "                left_error = self.left_tree.annotations[\"error\"]\n",
    "                right_error = self.right_tree.annotations[\"error\"]\n",
    "                \n",
    "                if (self.annotations[\"error\"] - (left_error + right_error)) < threshold:\n",
    "                    self.left_tree = None\n",
    "                    self.right_tree = None\n",
    "                    self.split = None\n",
    "                    self.is_node = True\n",
    "                    self.value = self.annotations[\"mean\"]\n",
    "                    \n",
    "                    return True\n",
    "                \n",
    "                return False\n",
    "            else:\n",
    "                left_was_pruned = self.left_tree._prune_to_smallest_subtree(threshold)\n",
    "                right_was_pruned = self.right_tree._prune_to_smallest_subtree(threshold)\n",
    "                \n",
    "                return left_was_pruned or right_was_pruned\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def prune_weakest_link(self, train_features, train_targets):\n",
    "        if self.is_node:\n",
    "            return 0., 0\n",
    "        \n",
    "        self.annotate_branch_errors(train_features, train_targets)\n",
    "        \n",
    "        trees, branch_errors, leaf_counts, errors = zip(*list(self.branch_errors()))\n",
    "        \n",
    "        branch_errors = np.array(branch_errors)\n",
    "        leaf_counts = np.array(leaf_counts)\n",
    "        errors = np.array(errors)\n",
    "        \n",
    "        alphas = (errors - branch_errors) / (leaf_counts - 1)\n",
    "        \n",
    "        weakest_alpha = np.min(alphas)\n",
    "        \n",
    "        pruneables = np.nonzero(alphas == weakest_alpha)\n",
    "        \n",
    "        for prune_index in pruneables:\n",
    "            prune_index = prune_index[0]\n",
    "            trees[prune_index].split = None\n",
    "            trees[prune_index].left_tree = None\n",
    "            trees[prune_index].right_tree = None\n",
    "            trees[prune_index].is_node = True\n",
    "            trees[prune_index].value = trees[prune_index].annotations[\"mean\"]\n",
    "            \n",
    "        return weakest_alpha, len(pruneables)\n",
    "\n",
    "    def branch_errors(self):\n",
    "        if not self.is_node:\n",
    "            yield self, self.annotations[\"branch_error\"], self.annotations[\"leaf_count\"], self.annotations[\"error\"]\n",
    "            \n",
    "            for tree, branch_error, leaf_count, error in self.left_tree.branch_errors():\n",
    "                yield tree, branch_error, leaf_count, error\n",
    "                \n",
    "            for tree, branch_error, leaf_count, error in self.right_tree.branch_errors():\n",
    "                yield tree, branch_error, leaf_count, error\n",
    "        \n",
    "    def annotate_errors(self, train_features, train_targets):\n",
    "        self.annotations[\"error\"] = ((train_targets.mean() - train_targets)**2).sum()\n",
    "        self.annotations[\"mean\"] = train_targets.mean()\n",
    "        \n",
    "        if not self.is_node:\n",
    "            left_split, right_split = decision_split_df(train_features, train_targets, self.split)\n",
    "\n",
    "            self.left_tree.annotate_errors(*left_split)\n",
    "            self.right_tree.annotate_errors(*right_split)\n",
    "            \n",
    "    def annotate_branch_errors(self, train_features, train_targets):\n",
    "        if self.is_node:\n",
    "            return rss_from_mean(train_targets), 1\n",
    "        else:\n",
    "            left_split, right_split = decision_split_df(train_features, train_targets, self.split)\n",
    "            \n",
    "            left_branch_error, left_leaf_count = self.left_tree.annotate_branch_errors(*left_split)\n",
    "            right_branch_error, right_leaf_count = self.right_tree.annotate_branch_errors(*right_split)\n",
    "            \n",
    "            self.annotations[\"branch_error\"] = left_branch_error + right_branch_error\n",
    "            self.annotations[\"leaf_count\"] = left_leaf_count + right_leaf_count\n",
    "            \n",
    "            return self.annotations[\"branch_error\"], self.annotations[\"leaf_count\"]\n",
    "            \n",
    "    def node_count(self):\n",
    "        if self.is_node:\n",
    "            return 1\n",
    "        \n",
    "        return 1 + self.left_tree.node_count() + self.right_tree.node_count()\n",
    "\n",
    "\n",
    "def make_stump(split, left_value, right_value):\n",
    "    return DecisionTree(split=split, left_tree=DecisionTree(value=left_value), right_tree=DecisionTree(value=right_value))\n",
    "\n",
    "def make_node(value):\n",
    "    return DecisionTree(value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7a8d3a-4636-49a2-959a-ea5f02d9309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_hdf(dirs.processed / \"book_features.h5\")\n",
    "targets_df = pd.read_hdf(dirs.processed / \"targets_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdd1640-c83b-406a-abd2-f50442d8779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val = feature_df.sample(frac=0.2, random_state=5).sort_index()\n",
    "val_index = feature_val.index\n",
    "\n",
    "feature_train = feature_df.drop(val_index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a6f4b2-7906-4703-be69-164d31041250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(df):\n",
    "    return df.loc[feature_train.index], df.loc[feature_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe43bfdd-4527-4c13-82fb-f7532cf5a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train, targets_val = make_split(targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339e9b4d-fc08-41bb-a081-dba7756d47aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>past_vol</th>\n",
       "      <th>wap1_mean</th>\n",
       "      <th>wap1_std</th>\n",
       "      <th>wap1_min</th>\n",
       "      <th>wap1_med</th>\n",
       "      <th>wap1_max</th>\n",
       "      <th>wap2_mean</th>\n",
       "      <th>wap2_std</th>\n",
       "      <th>wap2_min</th>\n",
       "      <th>wap2_med</th>\n",
       "      <th>wap2_max</th>\n",
       "      <th>spread_mean</th>\n",
       "      <th>spread_std</th>\n",
       "      <th>spread_min</th>\n",
       "      <th>spread_med</th>\n",
       "      <th>spread_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>1.001434</td>\n",
       "      <td>1.003923</td>\n",
       "      <td>1.004920</td>\n",
       "      <td>1.003661</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>1.001390</td>\n",
       "      <td>1.003821</td>\n",
       "      <td>1.005124</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>1.000232</td>\n",
       "      <td>1.000834</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.000192</td>\n",
       "      <td>1.001067</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>1.000878</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.996897</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>1.000876</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.999231</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>1.000159</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>1.000249</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.996629</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>0.996739</td>\n",
       "      <td>1.000231</td>\n",
       "      <td>0.996725</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>0.996681</td>\n",
       "      <td>1.000965</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">126</th>\n",
       "      <th>32750</th>\n",
       "      <td>0.003293</td>\n",
       "      <td>1.000025</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1.002136</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.998192</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>1.002215</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32751</th>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.998250</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>1.000736</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>1.000788</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32753</th>\n",
       "      <td>0.004104</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>1.000633</td>\n",
       "      <td>1.002376</td>\n",
       "      <td>1.006166</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>1.000632</td>\n",
       "      <td>1.002726</td>\n",
       "      <td>1.006178</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.001372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32763</th>\n",
       "      <td>0.003661</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>1.001788</td>\n",
       "      <td>1.002963</td>\n",
       "      <td>1.001790</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>1.000537</td>\n",
       "      <td>1.001814</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.001117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32767</th>\n",
       "      <td>0.002092</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.999178</td>\n",
       "      <td>1.000314</td>\n",
       "      <td>1.001058</td>\n",
       "      <td>1.000367</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>1.000457</td>\n",
       "      <td>1.001306</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225499 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  past_vol  wap1_mean  wap1_std  wap1_min  wap1_med  wap1_max  \\\n",
       "stock_id time_id                                                                \n",
       "0        5        0.004499   1.003725  0.000693  1.001434  1.003923  1.004920   \n",
       "         11       0.001204   1.000239  0.000262  0.999700  1.000232  1.000834   \n",
       "         16       0.002369   0.999542  0.000864  0.997224  0.999818  1.000878   \n",
       "         62       0.001894   0.999619  0.000258  0.999231  0.999586  1.000159   \n",
       "         97       0.010034   0.996629  0.001862  0.993168  0.996739  1.000231   \n",
       "...                    ...        ...       ...       ...       ...       ...   \n",
       "126      32750    0.003293   1.000025  0.000971  0.998281  0.999979  1.002136   \n",
       "         32751    0.003691   0.999582  0.000486  0.998250  0.999611  1.000736   \n",
       "         32753    0.004104   1.002476  0.001264  1.000633  1.002376  1.006166   \n",
       "         32763    0.003661   1.001809  0.000456  1.000562  1.001788  1.002963   \n",
       "         32767    0.002092   1.000272  0.000384  0.999178  1.000314  1.001058   \n",
       "\n",
       "                  wap2_mean  wap2_std  wap2_min  wap2_med  wap2_max  \\\n",
       "stock_id time_id                                                      \n",
       "0        5         1.003661  0.000781  1.001390  1.003821  1.005124   \n",
       "         11        1.000206  0.000272  0.999575  1.000192  1.001067   \n",
       "         16        0.999680  0.000862  0.996897  0.999751  1.000876   \n",
       "         62        0.999626  0.000317  0.999102  0.999598  1.000249   \n",
       "         97        0.996725  0.001979  0.992609  0.996681  1.000965   \n",
       "...                     ...       ...       ...       ...       ...   \n",
       "126      32750     0.999987  0.001037  0.998192  0.999978  1.002215   \n",
       "         32751     0.999585  0.000613  0.997950  0.999506  1.000788   \n",
       "         32753     1.002602  0.001303  1.000632  1.002726  1.006178   \n",
       "         32763     1.001790  0.000507  1.000537  1.001814  1.003009   \n",
       "         32767     1.000367  0.000465  0.999129  1.000457  1.001306   \n",
       "\n",
       "                  spread_mean  spread_std  spread_min  spread_med  spread_max  \n",
       "stock_id time_id                                                               \n",
       "0        5           0.000852    0.000212    0.000361    0.000876    0.001394  \n",
       "         11          0.000394    0.000157    0.000151    0.000351    0.000904  \n",
       "         16          0.000725    0.000164    0.000384    0.000718    0.001150  \n",
       "         62          0.000397    0.000130    0.000093    0.000373    0.000793  \n",
       "         97          0.001666    0.000446    0.000459    0.001735    0.002663  \n",
       "...                       ...         ...         ...         ...         ...  \n",
       "126      32750       0.000774    0.000214    0.000206    0.000786    0.001200  \n",
       "         32751       0.000878    0.000235    0.000392    0.000882    0.001570  \n",
       "         32753       0.000706    0.000228    0.000240    0.000688    0.001372  \n",
       "         32763       0.000530    0.000172    0.000066    0.000526    0.001117  \n",
       "         32767       0.000432    0.000125    0.000154    0.000412    0.000823  \n",
       "\n",
       "[225499 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50382d17-26fa-4279-8bf7-158f410cb5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(('past_vol', 0.003), False), (('wap1_mean', 1.0), False)], 0.001),\n",
       " ([(('past_vol', 0.003), False), (('wap1_mean', 1.0), True)], 0.002),\n",
       " ([(('past_vol', 0.003), True)], 0.0045)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTree(split=(\"past_vol\", 0.003), left_tree=make_stump((\"wap1_mean\", 1.), 0.0010, 0.0020), right_tree=DecisionTree(value=0.0045))\n",
    "\n",
    "list(tree.paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5205f2-34fd-4341-97fb-1d7c4399d33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4755109243894239"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(tree.classify(feature_train), targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4cbe619-9df1-4bac-aafa-e3f5f706102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tree(train_features, train_targets, min_observations=1, tqdm_iter=None):\n",
    "    if len(train_features) <= min_observations:\n",
    "        if len(train_features) == 0:\n",
    "            return make_node(0.)\n",
    "        \n",
    "        return make_node(train_targets.mean())\n",
    "    \n",
    "    # s_scores = np.zeros(len(train_features.columns), dtype=float)\n",
    "    # lits = np.zeros(len(train_features.columns), dtype=float\n",
    "    features = np.array(train_features.columns)\n",
    "    \n",
    "    best_splits = np.array([get_best_split(train_features[feature], train_targets) for feature in features])\n",
    "    \n",
    "    best_index = trial_splits(train_features.to_numpy(), train_targets.to_numpy(), best_splits)\n",
    "    \n",
    "#     for index, feature in enumerate(features):\n",
    "#         best_split = get_best_split(train_features[feature], train_targets)\n",
    "        \n",
    "#         less_mean = train_targets[train_features[feature] <= best_split].mean()\n",
    "#         greater_mean = train_targets[train_features[feature] > best_split].mean()\n",
    "        \n",
    "#         best_stump = make_stump((feature, best_split), less_mean, greater_mean)\n",
    "        \n",
    "#         rss_scores[index] = np.sum((best_stump.classify(train_features) - train_targets)**2)\n",
    "#         splits[index] = best_split\n",
    "    \n",
    "#     best_index = np.argmin(rss_scores)\n",
    "    \n",
    "    left_bool_index = train_features[features[best_index]] <= best_splits[best_index]\n",
    "    right_bool_index = train_features[features[best_index]] > best_splits[best_index]\n",
    "    \n",
    "    if len(train_features[left_bool_index]) == 0 or len(train_features[right_bool_index]) == 0:\n",
    "        return make_node(train_targets.mean())\n",
    "    \n",
    "    left_rss = rss_from_mean(train_targets[left_bool_index])\n",
    "    right_rss = rss_from_mean(train_targets[right_bool_index])\n",
    "    \n",
    "    if (left_rss + right_rss) > rss_from_mean(train_targets):\n",
    "        return make_node(train_targets.mean())\n",
    "    \n",
    "    if tqdm_iter is not None:\n",
    "        tqdm_iter.update(1)\n",
    "    \n",
    "    left_tree = fit_tree(train_features[left_bool_index], train_targets[left_bool_index], min_observations, tqdm_iter)\n",
    "    right_tree = fit_tree(train_features[right_bool_index], train_targets[right_bool_index], min_observations, tqdm_iter)\n",
    "    \n",
    "    return DecisionTree(split=(features[best_index], best_splits[best_index]), left_tree=left_tree, right_tree=right_tree)\n",
    "\n",
    "\n",
    "def get_best_split(train_feature, train_targets):\n",
    "    train_feature_np = train_feature.to_numpy()\n",
    "    train_targets_np = train_targets.to_numpy()\n",
    "    \n",
    "    splits = np.copy(train_targets_np)\n",
    "    \n",
    "    best_index = trial_splits(train_feature_np[:, None], train_targets_np, splits)\n",
    "    \n",
    "    return splits[best_index]\n",
    "\n",
    "\n",
    "def trial_splits(train_feature, train_targets, splits):\n",
    "    greater_matrix = train_feature > splits[None, :]\n",
    "    less_matrix = np.logical_not(greater_matrix)\n",
    "    \n",
    "    greater_matrix_sum = np.sum(greater_matrix, axis=0)\n",
    "    less_matrix_sum = np.sum(less_matrix, axis=0)\n",
    "    \n",
    "    greater_matrix_sum[greater_matrix_sum == 0] = 1\n",
    "    less_matrix_sum[less_matrix_sum == 0] = 1\n",
    "\n",
    "    greater_means = np.sum(train_targets[:, None] * greater_matrix, axis=0) / greater_matrix_sum\n",
    "    less_means = np.sum(train_targets[:, None] * less_matrix, axis=0) / less_matrix_sum\n",
    "    \n",
    "    greater_diffs = (greater_means[None, :] - train_targets[:, None]) * greater_matrix\n",
    "    less_diffs = (less_means[None, :] - train_targets[:, None]) * less_matrix\n",
    "    \n",
    "    rss_scores = np.sum(greater_diffs**2, axis=0) + np.sum(less_diffs**2, axis=0)\n",
    "    \n",
    "    return np.argmin(rss_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda3400a-5fe8-4b03-976d-c3da856adf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_train.loc[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1dc113-7119-4ee1-ae4b-de160d62900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d447584e1380418eb33bd79ce096f433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_id = 110\n",
    "\n",
    "train_x, train_y = feature_train.loc[stock_id], targets_train.loc[stock_id]\n",
    "val_x, val_y = feature_val.loc[stock_id], targets_val.loc[stock_id]\n",
    "\n",
    "with tqdm(leave=True) as pbar:\n",
    "    overfit_tree = fit_tree(feature_train.loc[stock_id], targets_train.loc[stock_id], min_observations=1, tqdm_iter=pbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d14c36-fae6-4c5f-8760-102f782b3078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overfit_tree.node_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b34c6ea4-8cbf-4851-9fde-b149c7448814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3031509888641468"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(overfit_tree.classify(feature_train.loc[stock_id]), targets_train.loc[stock_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23958e9e-b604-45d1-95e2-e832734146c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_cost(decision_tree, train_features, train_targets, tuning_param=0.):\n",
    "    if not decision_tree.is_node:\n",
    "        (train_features_left, train_targets_left), (train_features_right, train_targets_right) = decision_split_df(\n",
    "            train_features,\n",
    "            train_targets,\n",
    "            decision_tree.split\n",
    "        )\n",
    "        \n",
    "        left_cost = annotate_cost(decision_tree.left_tree, train_features_left, train_targets_left, tuning_param=tuning_param)\n",
    "        right_cost = annotate_cost(decision_tree.right_tree, train_features_right, train_targets_right, tuning_param=tuning_param)\n",
    "        \n",
    "        terminal_cost = left_cost + right_cost + tuning_param * decision_tree.annotations[\"node_count\"]\n",
    "        \n",
    "        as_node_cost = ((train_targets - train_targets.mean())**2).sum()\n",
    "        \n",
    "        decision_tree.annotations[\"cost\"] = terminal_cost - (as_node_cost + tuning_param)\n",
    "        \n",
    "        return left_cost + right_cost\n",
    "    else:\n",
    "        return ((train_targets - train_targets.mean())**2).sum()\n",
    "\n",
    "\n",
    "def annotate_node_counts(decision_tree):\n",
    "    if not decision_tree.is_node:\n",
    "        left_nodes = annotate_node_counts(decision_tree.left_tree)\n",
    "        right_nodes = annotate_node_counts(decision_tree.right_tree)\n",
    "\n",
    "        decision_tree.annotations[\"node_count\"] = left_nodes + right_nodes\n",
    "\n",
    "        return decision_tree.annotations[\"node_count\"]\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb52c1f-623d-431f-83ed-e6da957a212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate_node_counts(overfit_tree)\n",
    "\n",
    "# tune_param = 1e-6\n",
    "# annotate_cost(overfit_tree, feature_train.loc[stock_id], targets_train.loc[stock_id], tuning_param=tune_param)\n",
    "\n",
    "# ((overfit_tree.classify(feature_train.loc[stock_id]) - targets_train.loc[stock_id])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad33b5ee-9291-4492-b301-5871eb8d9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = overfit_tree.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32145240-0f03-4148-a5e1-be66ccc067a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.annotate_errors(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ba9660a-8aec-45d1-a496-5a54802a3ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0037236206849737405, 385)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.annotate_branch_errors(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "656392a1-0ce0-41e6-bd11-dd20c9196505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01780801951103141, 0.0037236206849737405)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.annotations[\"error\"], test.annotations[\"branch_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c37fca38-9aae-4498-bdb7-de6a5d1077db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01780801951103141"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ((test.annotations[\"mean\"] - train_y)**2).sum()\n",
    "((train_y.mean() - train_y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bf11ddf-e225-4e72-b87f-92a71b1628b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004465656952931462"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2a2bd8a-ec14-41f4-9cdc-d6a7b54568bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005752626179994373"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.left_tree.annotations[\"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e82712ef-972d-40c2-813e-c2b059e8612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.prune_to_smallest_subtree(feature_train.loc[stock_id], targets_train.loc[stock_id], threshold=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecfc47bc-606c-4bb2-91c0-cdc32966012f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.node_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "212ae6a4-0cad-435f-a507-bcb89eb174b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c17d4df96424fd995dc2e80c1cc4f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_alpha, pruned_count = test.prune_weakest_link(feature_train.loc[stock_id], targets_train.loc[stock_id])\n",
    "\n",
    "with tqdm() as pbar:\n",
    "    while pruned_count != 0:\n",
    "        _, pruned_count = test.prune_weakest_link(train_x, train_y)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1505f01d-c3d9-49d1-a1b3-9a533b6ac9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f39b0db5-d6d3-4e07-a6cf-8c4a7086ae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.node_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97cad4e8-1624-4002-adc7-18a7e5e59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate_node_counts(test)\n",
    "# annotate_cost(test, feature_train.loc[stock_id], targets_train.loc[stock_id], tuning_param=tune_param)\n",
    "# prune_more = test.prune_best_cost(feature_train.loc[stock_id], targets_train.loc[stock_id])\n",
    "\n",
    "# with tqdm() as pbar:\n",
    "#     while prune_more:\n",
    "#         annotate_node_counts(test)\n",
    "#         annotate_cost(test, feature_train.loc[stock_id], targets_train.loc[stock_id], tuning_param=tune_param)\n",
    "#         prune_more = test.prune_best_cost(feature_train.loc[stock_id], targets_train.loc[stock_id])\n",
    "#         pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef2893a4-8571-4e91-9662-f0d0c52a757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate_node_counts(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b6f5253-57b1-4e36-bf40-104b3e74a026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3031509037542305"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test.classify(feature_train.loc[stock_id]), targets_train.loc[stock_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
