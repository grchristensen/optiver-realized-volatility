{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9403b3-3c63-41a8-8a8e-eaba4bc4f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from optiver import Directories\n",
    "\n",
    "dirs = Directories(\"../..\")\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2018f2-c67d-40be-a783-6f8e78be509f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Competition Data\n",
    "\n",
    "The task that we are given in this competition is to predict the realized volatility of a stock within 10 minutes, given 10 minutes of prior data for that stock. To do this we have access to order book and trade data over a 10 minute window for a variety of stocks, as well as the realized volatility for the stock in the next 10 minutes. This makes the task a regression problem where the input is the order book and trades and the output is the predicted volatility in the next 10 minutes. Success in this competition will require mining good features from the input data and choosing a good model to map features to outputs. There are 112 stocks to work with and 3830 data points per stock.\n",
    "\n",
    "## Explanation of Files\n",
    "\n",
    "This is an edited version of the explanation given at https://www.kaggle.com/c/optiver-realized-volatility-prediction/data. There are three main files of interest in the competition data.\n",
    "\n",
    "**book_train.parquet** A parquet file containing book order data for the most competitive buy and sell orders of each stock. \n",
    "- `stock_id` - ID code for the stock. Not all stock IDs exist in every time bucket. ~~It is expected that the same stock IDs will be present in the testing data, so we can train models that are particular to each stock, rather than trying to create a model that works for any stock.~~ We probably have to train a model that works for any stock, because our model will be tested on real market data.\n",
    "- `time_id` - ID code for the time bucket. Time IDs are not necessarily sequential but are consistent across all stocks.\n",
    "- `seconds_in_bucket` - Number of seconds from the start of the bucket, always starting from 0.\n",
    "- `bid_price[1/2]` - Normalized prices of the most/second most competitive buy level.\n",
    "- `ask_price[1/2]` - Normalized prices of the most/second most competitive sell level.\n",
    "- `bid_size[1/2]` - The number of shares on the most/second most competitive buy level.\n",
    "- `ask_size[1/2]` - The number of shares on the most/second most competitive sell level.\n",
    "**trade_train.parquet** A parquet file containing data on trades that are actually executed. Usually, in the market, there are more passive buy/sell intention updates (book updates) than actual trades, therefore one may expect this file to be more sparse than the order book.\n",
    "- `stock_id` - Same as above.\n",
    "- `time_id` - Same as above.\n",
    "- `seconds_in_bucket` - Same as above. Note that since trade and book data are taken from the same time window and trade data is more sparse in general, this field is not necessarily starting from 0.\n",
    "- `price` - The average price of executed transactions happening in one second. Prices have been normalized and the average has been weighted by the number of shares traded in each transaction.\n",
    "- `size` - The sum number of shares traded.\n",
    "- `order_count` - The number of unique trade orders taking place.\n",
    "**train.csv** The ground truth values for realized volatility.\n",
    "- `stock_id` - Same as above.\n",
    "- `time_id` - Same as above.\n",
    "- `target` - The realized volatility computed over the 10 minute window following the feature data under the same stock/time_id. There is no overlap between feature and target data.\n",
    "\n",
    "## Data Splitting\n",
    "\n",
    "Portions of the data need to be reserved for testing our most promising models before submission. We will take 20 stocks and make sure that they are not seen at all by the training process, so that we can gauge how well our methods will work on new stocks. Out of the rest of the data, 20% of the `time_id`s for each `stock_id` will be reserved in a test set for stocks that have already been seen. It would also be a good idea to see how the model fares on real market data before the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdbff24-6bdd-44ef-9c90-8e560cd3c612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 112/112 [00:14<00:00,  7.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 112/112 [00:03<00:00, 36.62it/s]\n"
     ]
    }
   ],
   "source": [
    "stocks = os.listdir(dirs.raw / \"book_train.parquet\")\n",
    "# Sorting the directory names ensures that this will always provide the same split for a given seed.\n",
    "stocks.sort()\n",
    "\n",
    "# These stocks are allowed to be seen by the training process.\n",
    "train_stocks = sample(stocks, len(stocks) - 20)\n",
    "\n",
    "# We save the split in a plain text file in case we want to commit it and ensure we can replicate the split.\n",
    "with open(dirs.splits / \"train_stocks.txt\", 'w+') as f:\n",
    "    f.write(''.join([train_stock + '\\n' for train_stock in train_stocks[:-1]]))\n",
    "    f.write(train_stocks[-1])\n",
    "\n",
    "\n",
    "def reserve_stocks(src, train_dest, reserved_dest):\n",
    "    \"\"\"Split the stock data found in the source directory into a training directory and reserved directory.\"\"\"\n",
    "    os.makedirs(train_dest, exist_ok=True)\n",
    "    os.makedirs(reserved_dest, exist_ok=True)\n",
    "\n",
    "    for stock in tqdm(stocks):\n",
    "        dest = train_dest if stock in train_stocks else reserved_dest\n",
    "        copy_tree(os.fspath(src / stock), os.fspath(dest / stock))\n",
    "\n",
    "\n",
    "reserve_stocks(dirs.raw / \"book_train.parquet\", dirs.interim / \"book_train.parquet\", dirs.interim / \"book_reserved.parquet\")\n",
    "reserve_stocks(dirs.raw / \"trade_train.parquet\", dirs.interim / \"trade_train.parquet\", dirs.interim / \"trade_reserved.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40f77a-8078-4623-80e6-b0945010a13e",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training split is for the order book and trade data is located in `data/interim/book_train.parquet` and `data/interim/trade_train.parquet`, respectively. Similar locations are given to the reserved split. This is a different convention from the raw competition data, where `book_train.parquet` for example contains all the training data for order books.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Before we reserve the testing set for each stock, we are going to process the data a bit, to make it easier to index. The parquet file for each stock will become an HDF5 file and the dataframes will be indexed by things such as `stock_id`, `time_id`, and `seconds_in_bucket`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f3afad-841d-4ceb-8643-63977380aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 92/92 [01:21<00:00,  1.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 92/92 [00:04<00:00, 21.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 20/20 [00:15<00:00,  1.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 13.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_input(src, dest):\n",
    "    \"\"\"\n",
    "    Read all parquet files and reindex them by time_id and seconds_in_bucket before\n",
    "    converting them to HDF format.\n",
    "    \"\"\"\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    \n",
    "    for parquet_file in tqdm(os.listdir(src)):\n",
    "        df = pd.read_parquet(src / parquet_file)\n",
    "        \n",
    "        df.index = pd.MultiIndex.from_frame(df[['time_id', 'seconds_in_bucket']])\n",
    "        # Drop old columns that are now represented as indices.\n",
    "        df = df.drop(columns=['time_id', 'seconds_in_bucket'])\n",
    "        \n",
    "        # The parquet filename format is `stock_id=#`, but we don't want the =\n",
    "        # character in the filename so we change it to `stock_#`.\n",
    "        hdf_file = f\"stock_{parquet_file[9:]}.h5\"\n",
    "        \n",
    "        df.to_hdf(dest / hdf_file, key=hdf_file[:-3])\n",
    "\n",
    "\n",
    "def process_targets(csv_file):\n",
    "    \"\"\"Read the CSV file and return a series containing targets and indexed by stock id and time_id.\"\"\"\n",
    "    targets = pd.read_csv(csv_file)\n",
    "\n",
    "    targets.index = pd.MultiIndex.from_frame(targets[['stock_id', 'time_id']])\n",
    "    # We decide to turn the dataframe into a series since there's only one column.\n",
    "    targets = targets[\"target\"]\n",
    "    \n",
    "    return targets\n",
    "\n",
    "\n",
    "process_input(dirs.interim / \"book_train.parquet\", dirs.interim / \"processed\" / \"book_train\")\n",
    "process_input(dirs.interim / \"trade_train.parquet\", dirs.interim / \"processed\" / \"trade_train\")\n",
    "\n",
    "# Since we won't need to do anything with the reserved set after indexing it, we can immediately save it\n",
    "# to the processed directory.\n",
    "process_input(dirs.interim / \"book_reserved.parquet\", dirs.processed / \"book_reserved\")\n",
    "process_input(dirs.interim / \"trade_reserved.parquet\", dirs.processed / \"trade_reserved\")\n",
    "\n",
    "targets = process_targets(dirs.raw / \"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abcfc8-2a8f-4fa6-a416-44d9773ec045",
   "metadata": {},
   "source": [
    "After the data has been reindexed, the final split can be made. There will then be three types of files in the `data/processed` directory:\n",
    "\n",
    "**book_[train/test/reserved]** A directory of HDF files containing dataframes of book order data for each stock. Dataframes are indexed by `time_id` and `seconds_in_bucket`.\n",
    "\n",
    "**trade_[train/test/reserved]** Same as above but for the trade data of each stock.\n",
    "\n",
    "**targets_[train/test/reserved]** An HDF file containing a series of realized volatility targets. The series is indexed by `stock_id` and `time_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabc508a-c2cb-44cf-ae55-e6296c3e3cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 92/92 [04:12<00:00,  2.75s/it]\n",
      "100%|████████████████████████████████████████████████████████████| 92/92 [00:49<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_stock_id(stock_id: str):\n",
    "    # Format is stock_id=#, we need to get rid of 'stock_id='\n",
    "    return int(stock_id[9:])\n",
    "\n",
    "\n",
    "def split_index(df, index):\n",
    "    split_2 = df[index]\n",
    "    split_1 = df.drop(split_2.index)\n",
    "    \n",
    "    return split_1, split_2\n",
    "\n",
    "\n",
    "reserved_stock_ids = [parse_stock_id(stock) for stock in stocks if stock not in train_stocks]\n",
    "\n",
    "train_targets, reserved_targets = split_index(targets, reserved_stock_ids)\n",
    "train_targets, test_targets = split_index(train_targets, train_targets.sample(frac=0.2, random_state=0).sort_index().index)\n",
    "\n",
    "train_targets.to_hdf(dirs.processed / \"targets_train.h5\", key=\"targets_train\")\n",
    "test_targets.to_hdf(dirs.processed / \"targets_test.h5\", key=\"targets_test\")\n",
    "reserved_targets.to_hdf(dirs.processed / \"targets_reserved.h5\", key=\"targets_reserved\")\n",
    "\n",
    "\n",
    "def make_test_split(directory, train_directory, test_directory, trade=False):\n",
    "    \"\"\"Take 20% of every training dataframe and reserve it in a special testing set.\"\"\"\n",
    "    for hdf_file in tqdm(os.listdir(directory)):\n",
    "        # filename format is stock_#.h5\n",
    "        stock_id = int(hdf_file[6:-3])\n",
    "        \n",
    "        train_df = pd.read_hdf(directory / hdf_file)\n",
    "        \n",
    "        test_index = test_targets[stock_id].index\n",
    "        \n",
    "        # Trade files may not have every time_id, since it's possible that there were no trades for certain time periods.\n",
    "        if trade:\n",
    "            available_time_ids = set(train_df.index.get_level_values(\"time_id\"))\n",
    "            if len(test_index) != len(available_time_ids):\n",
    "                test_index = [index for index in test_index if index in available_time_ids]\n",
    "        \n",
    "        test_df = train_df.loc[test_index]\n",
    "        train_df = train_df.drop(test_index)\n",
    "        \n",
    "        os.makedirs(train_directory, exist_ok=True)\n",
    "        os.makedirs(test_directory, exist_ok=True)\n",
    "        \n",
    "        df_name = f\"stock_{stock_id}\"\n",
    "        train_df.to_hdf(train_directory / hdf_file, key=df_name)\n",
    "        test_df.to_hdf(test_directory / hdf_file, key=df_name)\n",
    "\n",
    "\n",
    "make_test_split(dirs.interim / \"processed\" / \"book_train\", dirs.processed / \"book_train\", dirs.processed / \"book_test\")\n",
    "make_test_split(dirs.interim / \"processed\" / \"trade_train\", dirs.processed / \"trade_train\", dirs.processed / \"trade_test\", trade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a1611-7afc-4110-8234-4bf231b1ce19",
   "metadata": {},
   "source": [
    "Here is an example of training data for `stock_id=96`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1181dc-9727-437e-bb8a-1d670ce4842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order book:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>0</th>\n",
       "      <td>1.000766</td>\n",
       "      <td>1.001283</td>\n",
       "      <td>1.000747</td>\n",
       "      <td>1.001301</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000766</td>\n",
       "      <td>1.001283</td>\n",
       "      <td>1.000747</td>\n",
       "      <td>1.001301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000932</td>\n",
       "      <td>1.001430</td>\n",
       "      <td>1.000914</td>\n",
       "      <td>1.001504</td>\n",
       "      <td>214</td>\n",
       "      <td>21</td>\n",
       "      <td>214</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001061</td>\n",
       "      <td>1.001578</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>1.001596</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.001061</td>\n",
       "      <td>1.001578</td>\n",
       "      <td>1.000747</td>\n",
       "      <td>1.001596</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">32767</th>\n",
       "      <th>593</th>\n",
       "      <td>0.999157</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.999137</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.999157</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>0.999137</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>100</td>\n",
       "      <td>201</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.999157</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.999137</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.999137</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.999015</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1376692 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
       "time_id seconds_in_bucket                                                   \n",
       "5       0                    1.000766    1.001283    1.000747    1.001301   \n",
       "        1                    1.000766    1.001283    1.000747    1.001301   \n",
       "        2                    1.000932    1.001430    1.000914    1.001504   \n",
       "        4                    1.001061    1.001578    1.000969    1.001596   \n",
       "        5                    1.001061    1.001578    1.000747    1.001596   \n",
       "...                               ...         ...         ...         ...   \n",
       "32767   593                  0.999157    0.999543    0.999137    0.999563   \n",
       "        594                  0.999157    0.999523    0.999137    0.999563   \n",
       "        595                  0.999157    0.999503    0.999137    0.999563   \n",
       "        596                  0.999137    0.999503    0.999117    0.999563   \n",
       "        598                  0.999035    0.999279    0.999015    0.999442   \n",
       "\n",
       "                           bid_size1  ask_size1  bid_size2  ask_size2  \n",
       "time_id seconds_in_bucket                                              \n",
       "5       0                         14          1         24          1  \n",
       "        1                          1          1         24          1  \n",
       "        2                        214         21        214         49  \n",
       "        4                         10          1         14         38  \n",
       "        5                        150          1          2         38  \n",
       "...                              ...        ...        ...        ...  \n",
       "32767   593                      100        100        100        100  \n",
       "        594                      100        201        100        100  \n",
       "        595                      100        102        100        100  \n",
       "        596                      100        102         28        100  \n",
       "        598                        1        100         31         28  \n",
       "\n",
       "[1376692 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trades:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>0</th>\n",
       "      <td>1.001216</td>\n",
       "      <td>369</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.001410</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001434</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.001109</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000990</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">32767</th>\n",
       "      <th>588</th>\n",
       "      <td>0.999726</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0.999604</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0.999462</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.999360</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.999137</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352539 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              price  size  order_count\n",
       "time_id seconds_in_bucket                             \n",
       "5       0                  1.001216   369           12\n",
       "        2                  1.001410   162           10\n",
       "        4                  1.001434    22            4\n",
       "        9                  1.001109    47            6\n",
       "        23                 1.000990    57            7\n",
       "...                             ...   ...          ...\n",
       "32767   588                0.999726     1            1\n",
       "        591                0.999604    31            1\n",
       "        592                0.999462    14            2\n",
       "        593                0.999360   100            2\n",
       "        598                0.999137   100            2\n",
       "\n",
       "[352539 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target realized volatility:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time_id\n",
       "5        0.005130\n",
       "11       0.002393\n",
       "16       0.003085\n",
       "62       0.002936\n",
       "72       0.006340\n",
       "           ...   \n",
       "32750    0.002326\n",
       "32751    0.004332\n",
       "32753    0.002848\n",
       "32763    0.004951\n",
       "32767    0.003124\n",
       "Name: target, Length: 3074, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_96_book = pd.read_hdf(dirs.processed / \"book_train\" / \"stock_96.h5\")\n",
    "stock_96_trades = pd.read_hdf(dirs.processed / \"trade_train\" / \"stock_96.h5\")\n",
    "stock_96_targets = pd.read_hdf(dirs.processed / \"targets_train.h5\")[96]\n",
    "\n",
    "print(\"Order book:\")\n",
    "display(stock_96_book)\n",
    "print(\"Trades:\")\n",
    "display(stock_96_trades)\n",
    "print(\"Target realized volatility:\")\n",
    "display(stock_96_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
